{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from geopy import Point, distance\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pmdarima\n",
    "from scipy import stats\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import util\n",
    "from pandarallel import pandarallel\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pmdarima.arima import auto_arima\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts=[\"https://elastic.tccurbstads.com:443\"],\n",
    "    basic_auth=(\"elastic\", \"!@ContaElastic\")\n",
    ")\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def isPointInShape(row):\n",
    "    response = es.search(index='test123456789', query={\n",
    "        \"bool\": {\n",
    "            \"must\": [{\n",
    "                \"match\": {\n",
    "                    \"COD\": row['COD_LINHA']\n",
    "                }\n",
    "            }],\n",
    "            \"filter\": {\n",
    "                \"geo_distance\": {\n",
    "                    \"distance\": \"300m\",\n",
    "                    \"coordinate\": {\n",
    "                        \"lat\": row['LAT'], \"lon\": row['LON']\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }})\n",
    "\n",
    "    if response['hits']['total']['value'] <= 0:\n",
    "        return\n",
    "\n",
    "    hits = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    if len(hits) <= 1:\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(hits)\n",
    "\n",
    "    df['distance'] = df.apply(lambda row1: distance.geodesic(\n",
    "        (row1['coordinate']['coordinates'][1], row1['coordinate']['coordinates'][0]), (row['LAT'], row['LON'])).m, axis=1)\n",
    "\n",
    "    df.sort_values(by=['distance'], inplace=True, ascending=True)\n",
    "\n",
    "    df = df.groupby(['SHP']).head(2)\n",
    "\n",
    "    df['closestDirection'] = df.apply(\n",
    "        lambda row1: row1['direction'] - row['direction'], axis=1).abs().mean()\n",
    "\n",
    "    df.sort_values(by=['closestDirection'], inplace=True, ascending=True)\n",
    "    df = df[df['SHP'] == df['SHP'].iloc[0]]\n",
    "\n",
    "    p3 = np.array([row['LAT'], row['LON']])\n",
    "\n",
    "    if (len(df) <= 1):\n",
    "        return\n",
    "\n",
    "    p1 = np.array([df['coordinate'].iloc[0]['coordinates']\n",
    "                   [1], df['coordinate'].iloc[0]['coordinates'][0]])\n",
    "\n",
    "    p2 = np.array([df['coordinate'].iloc[1]['coordinates']\n",
    "\n",
    "                   [1], df['coordinate'].iloc[1]['coordinates'][0]])\n",
    "\n",
    "    l2 = np.sum((p1-p2)**2)\n",
    "    t = np.sum((p3 - p1) * (p2 - p1)) / l2\n",
    "    projection = p1 + t * (p2 - p1)\n",
    "\n",
    "    percentage = np.sqrt(np.sum((projection - p1)**2)) / np.sqrt(l2)\n",
    "    finalPercentage = df['percentage'].iloc[0] * \\\n",
    "        (1-percentage) + df['percentage'].iloc[1] * percentage\n",
    "\n",
    "    return finalPercentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93edff9fa8684231a90eae6738edf7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=956), Label(value='0 / 956'))), HBâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = lzma.open(\n",
    "    \"../data/veiculos/2023_05_03_veiculos.json.xz\", mode=\"rt\").read()\n",
    "\n",
    "df = pd.read_json(file, lines=True)\n",
    "\n",
    "df = df[df['COD_LINHA'] == '469']\n",
    "\n",
    "df[\"LAT\"].replace(\",\", \".\", regex=True, inplace=True)\n",
    "df[\"LAT\"] = df[\"LAT\"].apply(pd.to_numeric)\n",
    "df[\"LON\"].replace(\",\", \".\", regex=True, inplace=True)\n",
    "df[\"LON\"] = df[\"LON\"].apply(pd.to_numeric)\n",
    "df[\"DTHR\"] = pd.to_datetime(\n",
    "    df[\"DTHR\"], format=\"%d/%m/%Y %H:%M:%S\").dt.tz_localize(\"America/Sao_Paulo\")\n",
    "\n",
    "df['point'] = df.apply(lambda row: Point(\n",
    "    latitude=row['LAT'], longitude=row['LON']), axis=1)\n",
    "\n",
    "df['point_next'] = df.groupby(['COD_LINHA'])[\n",
    "    'point'].shift(1)\n",
    "df.loc[df['point_next'].isna(), 'point_next'] = None\n",
    "\n",
    "df['direction'] = df.apply(lambda row: util.calc_bearing(\n",
    "    (row['point'].latitude, row['point'].longitude), (row['point_next'].latitude, row['point_next'].longitude)) if row['point_next'] is not None else float(0), axis=1)\n",
    "\n",
    "df.drop(columns=['point_next'], inplace=True)\n",
    "\n",
    "df[\"percentage\"] = df.parallel_apply(\n",
    "    lambda row: isPointInShape(row), axis=1)\n",
    "\n",
    "df = df[df['percentage'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8047423485664077\n",
      "15.559721167659987\n"
     ]
    }
   ],
   "source": [
    "test = df\n",
    "\n",
    "bus = test[df['VEIC'] == 'DL317']\n",
    "\n",
    "# put the time as an percentage of the day\n",
    "x = x.values.reshape(-1, 1)\n",
    "\n",
    "y = bus['percentage']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "r2 = model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-pre-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
